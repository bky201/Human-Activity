{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpLGU2RtmjW1"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import glob\n",
    "import os\n",
    "#import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1259,
     "status": "ok",
     "timestamp": 1590831375625,
     "user": {
      "displayName": "BEKRY MOHAMMEDDAWA",
      "photoUrl": "https://lh6.googleusercontent.com/-7j4JARNyQ3c/AAAAAAAAAAI/AAAAAAAAAIs/zlpWr3A2OcI/s64/photo.jpg",
      "userId": "03084319400094525820"
     },
     "user_tz": -120
    },
    "id": "Jp5XJfoKmjW_",
    "outputId": "9becfa22-02f1-4525-c570-e54ad97fcf65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BKY\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.neighbors.nearest_centroid module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1247,
     "status": "ok",
     "timestamp": 1590831375628,
     "user": {
      "displayName": "BEKRY MOHAMMEDDAWA",
      "photoUrl": "https://lh6.googleusercontent.com/-7j4JARNyQ3c/AAAAAAAAAAI/AAAAAAAAAIs/zlpWr3A2OcI/s64/photo.jpg",
      "userId": "03084319400094525820"
     },
     "user_tz": -120
    },
    "id": "Nkdxzt2zNOfl",
    "outputId": "c8769e2d-22ee-4203-a650-845e30386e45"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e70ec19a6cdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Loading the Drive helper and mount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#HERE Will prompt for authorisation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#Loading the Drive helper and mount\n",
    "from google.colab import drive\n",
    "#HERE Will prompt for authorisation\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxWDvN1MmjXK"
   },
   "outputs": [],
   "source": [
    "def subject_cross_validation(X, Y, groups, classifier):\n",
    "    f1 = []\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    for train_index, test_index in logo.split(X, Y, groups=groups):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        f1.append(f1_score(y_true=y_test, y_pred=y_pred, average='micro'))\n",
    "    return np.mean(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWNNlVlmmjXR"
   },
   "outputs": [],
   "source": [
    "# cv_strategy can be iid or sbj for k-fold cv and subject cv respectively\n",
    "\n",
    "def apply_classifiers(dataset_path, models, cv_strategy):\n",
    "\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(dataset_path, x)), os.listdir(dataset_path)))\n",
    "\n",
    "    for folder in folders:\n",
    "\n",
    "        results = dict()\n",
    "        p = os.path.join(dataset_path, folder)\n",
    "\n",
    "        files = glob.glob('{0}/*.csv'.format(p))\n",
    "        # print(files)\n",
    "\n",
    "        if not files:\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "\n",
    "            file_name = os.path.basename(os.path.splitext(file)[0])\n",
    "\n",
    "            win_size = float(3)\n",
    "            print(win_size)\n",
    "\n",
    "            dataset = pd.read_csv(file, sep='\\t')\n",
    "            groups = dataset['group']\n",
    "            X = dataset.iloc[:, 1:-1].values\n",
    "\n",
    "            Y = dataset.iloc[:, -1].values\n",
    "\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                f1 = 0\n",
    "\n",
    "                #if cv_strategy == 'sbj':\n",
    "\n",
    "                f1 = subject_cross_validation(X, Y, groups, model)\n",
    "\n",
    "                #else:\n",
    "\n",
    "                #f1 = cross_val_score(estimator=model, X=X, y=Y,cv=KFold(n_splits=10, shuffle=True, random_state=1), scoring='f1_micro',n_jobs=-1).mean()\n",
    "\n",
    "                if win_size in results:\n",
    "                    results[win_size].append(f1)\n",
    "                else:\n",
    "                    results[win_size] = [f1]\n",
    "\n",
    "        # export as csv file\n",
    "\n",
    "        results = collections.OrderedDict(sorted(results.items()))\n",
    "\n",
    "        final = []\n",
    "        col = list(models.keys())\n",
    "        col.insert(0, \"window-size\")\n",
    "        final.append(col)\n",
    "        for k, v in results.items():\n",
    "            tmp = []\n",
    "            tmp.append([k])\n",
    "            tmp.append(v)\n",
    "            flattened = [val for sublist in tmp for val in sublist]\n",
    "            final.append(flattened)\n",
    "\n",
    "        output_name = ''\n",
    "        #if cv_strategy == 'sbj':\n",
    "\n",
    "        output_name = folder + '-' + 'ALLsubjective'\n",
    "\n",
    "        #else:\n",
    "\n",
    "        #output_name = folder + '-' + 'iid'\n",
    "\n",
    "        np.savetxt(os.path.join(os.path.dirname('/content/drive/My Drive/sub1/Overlapping_windowed'), 'Results', output_name + '.csv'), final, delimiter=',',\n",
    "                   fmt='%s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9Ondfz9mjXZ"
   },
   "outputs": [],
   "source": [
    "models = {'RF': RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1525057,
     "status": "error",
     "timestamp": 1590832899488,
     "user": {
      "displayName": "BEKRY MOHAMMEDDAWA",
      "photoUrl": "https://lh6.googleusercontent.com/-7j4JARNyQ3c/AAAAAAAAAAI/AAAAAAAAAIs/zlpWr3A2OcI/s64/photo.jpg",
      "userId": "03084319400094525820"
     },
     "user_tz": -120
    },
    "id": "AbrXFjm1mjXh",
    "outputId": "fd451a73-d598-45f3-ed7c-957a23d23055"
   },
   "outputs": [],
   "source": [
    "#if (len(sys.argv) < 2):\n",
    "  #  print('Please enter the path of datasets')\n",
    "  #  exit()\n",
    "#elif (not os.path.exists(sys.argv[1])):\n",
    "#    print(\"This path does not exist!!\")\n",
    "#    exit()\n",
    "\n",
    "#else:\n",
    "dataset_path = r\"/content/drive/My Drive/sub1/ALL\"\n",
    "\n",
    "apply_classifiers(dataset_path=dataset_path, models=models, cv_strategy='sbj')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3-ALL-Subjectwise_ideal_Classification.ipynb",
   "provenance": [
    {
     "file_id": "1-Q972Dk-yZuoYT9RA0jsoHXTM28ASrDe",
     "timestamp": 1590610979047
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
