{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JK1wiYzYIxCK"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import collections\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39184,
     "status": "ok",
     "timestamp": 1590799556318,
     "user": {
      "displayName": "BEKRY MOHAMMEDDAWA",
      "photoUrl": "https://lh6.googleusercontent.com/-7j4JARNyQ3c/AAAAAAAAAAI/AAAAAAAAAIs/zlpWr3A2OcI/s64/photo.jpg",
      "userId": "03084319400094525820"
     },
     "user_tz": -120
    },
    "id": "eMqZnTcFI1Ma",
    "outputId": "fd551f65-a5c5-4a3d-897e-b1a0af00a236"
   },
   "outputs": [],
   "source": [
    "from numba.typed import List\n",
    "from numba import jit, njit, vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39166,
     "status": "ok",
     "timestamp": 1590799556321,
     "user": {
      "displayName": "BEKRY MOHAMMEDDAWA",
      "photoUrl": "https://lh6.googleusercontent.com/-7j4JARNyQ3c/AAAAAAAAAAI/AAAAAAAAAIs/zlpWr3A2OcI/s64/photo.jpg",
      "userId": "03084319400094525820"
     },
     "user_tz": -120
    },
    "id": "L6CPZsFqIxCU",
    "outputId": "90507f9e-85b3-4f7a-eea0-68c512f50d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "sample_rate = 50  # number of observation per second based on dataset documentation(150 samples in 3 second)\n",
    "\n",
    "sliding_size = int((1/3) * sample_rate)  # number of skipped datapoints to start next window\n",
    "print(sliding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nsLxSb-5IxCa"
   },
   "source": [
    "# Feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dr03fDIIxCc"
   },
   "outputs": [],
   "source": [
    "@njit()\n",
    "def mean_crossing_rate(col):\n",
    "    # col = np.array(values)\n",
    "    normalized = col - col.mean()  # to make elements of array possitive or negetive\n",
    "    return ((normalized[:-1] * col[1:]) < 0).sum()  # Zero-Crossing_rate\n",
    "\n",
    "@njit()\n",
    "def iqr(window):  # inter-quartile range\n",
    "    Q1 = np.median(window[:len(window)//2])  # First quartile (Q1) \n",
    "    Q3 = np.median(window[len(window)//2:])  # Third quartile (Q3) \n",
    "    IQR = Q3 - Q1 # Interquartile range (IQR) \n",
    "    return(IQR) \n",
    "@njit()\n",
    "def calc_sma_for_window(data):\n",
    "    return np.sum(data) / len(data)  \n",
    "@njit()\n",
    "def get_min(x):\n",
    "    m = np.min(x)\n",
    "    return m\n",
    "@njit()\n",
    "def get_max(x):\n",
    "    m = np.max(x)\n",
    "    return m\n",
    "@njit()\n",
    "def get_mean(x):\n",
    "    m = np.mean(x)\n",
    "    return m\n",
    "@njit()\n",
    "def get_var(x):\n",
    "    m = np.var(x)\n",
    "    return m\n",
    "@njit()\n",
    "def get_mean(x):\n",
    "    m = np.mean(x)\n",
    "    return m\n",
    "@njit()\n",
    "def get_sum(x):\n",
    "    m = x.sum()\n",
    "    return m \n",
    "@njit()\n",
    "def get_median(x):\n",
    "    m = np.median(x)\n",
    "    return m \n",
    "@njit()\n",
    "def get_std(x):\n",
    "    m = np.median(x)\n",
    "    return m \n",
    "@njit()\n",
    "def get_rng(x):\n",
    "    n = np.max(x)\n",
    "    m = np.min(x)\n",
    "    z = n-m\n",
    "    return z \n",
    "\n",
    "def get_rms(x, axis=None):\n",
    "    return np.sqrt(np.mean(x ** 2, axis=axis))\n",
    "\n",
    "def calc_sma_for_window(data):\n",
    "    return np.sum(data) / len(data)\n",
    "\n",
    "\n",
    "def calc_sma_adv_for_window(data):\n",
    "    return np.sum(data - np.mean(data) / len(data))\n",
    "\n",
    "\n",
    "def calc_absolutes_for_list(list):\n",
    "    return ([abs(i) for i in list])\n",
    "\n",
    "def get_sma(data): \n",
    "    sma_sim = calc_sma_for_window(data)\n",
    "    sma_adv = calc_sma_adv_for_window(data)\n",
    "\n",
    "    sma_sim_abs = calc_sma_for_window(calc_absolutes_for_list(data))\n",
    "    sma_adv_abs = calc_sma_adv_for_window(calc_absolutes_for_list(data))\n",
    "\n",
    "    return sma_sim, sma_adv, sma_sim_abs, sma_adv_abs\n",
    "\n",
    "def get_entropy(Y):\n",
    "    \"\"\"\n",
    "    Also known as Shanon Entropy\n",
    "    Reference: https://en.wikipedia.org/wiki/Entropy_(information_theory)\n",
    "    \"\"\"\n",
    "    unique, count = np.unique(Y, return_counts=True, axis=0)\n",
    "    prob = count/len(Y)\n",
    "    en = np.sum((-1)*prob*np.log2(prob))\n",
    "    return en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Energy(frame):\n",
    "    return sum( [ abs(x)**2 for x in frame ] ) / len(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction and Vector_Normalization on signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Features(window):# mean, std,max,min and zero-crossing-rate\n",
    "    wind = window.iloc[:, :-1]\n",
    "    win = np.array(wind)\n",
    "    \n",
    "    data_normalized = preprocessing.normalize(win, norm  = 'l1') # normalization on signal\n",
    "    win = data_normalized\n",
    "    features = []\n",
    "    \n",
    "    features.append(get_mean(win))\n",
    "    features.append(get_median(win))\n",
    "    features.append(get_std(win))\n",
    "    features.append(get_min(win))\n",
    "    features.append(get_max(win))\n",
    "    features.append(get_sum(win))\n",
    "    features.append(get_entropy(win))\n",
    "    mean_crossing = [mean_crossing_rate(win[:, i]) for i in range(win.shape[1])]\n",
    "    features.append(np.array(mean_crossing))\n",
    "    IQR = iqr(win)\n",
    "    features.append(np.array(IQR))\n",
    "    energy_measure = Energy(win)\n",
    "    features.append(np.array(energy_measure))\n",
    " \n",
    "\n",
    "    \n",
    "    features = np.hstack(features).tolist()\n",
    "    \n",
    "    label = window.iloc[:, -1].mode()[0]  ## select the most frequent label as the label of the window\n",
    "    features.append(label)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BoePfFWVIxCh"
   },
   "outputs": [],
   "source": [
    "def windowing_dataset(dataset, win_size, feature_extraction_function, subject_id, overlap=False):\n",
    "    windowed_dataset = []\n",
    "    win_count = 0\n",
    "    if overlap:\n",
    "        step_size = sliding_size  # for Overlapping technique\n",
    "    else:\n",
    "        step_size = win_size  # for Non-overlapping technique\n",
    "\n",
    "    for index in range(0, dataset.shape[0], step_size):\n",
    "        start = index\n",
    "        end = start + win_size\n",
    "        # to assure all of windows are equal in size\n",
    "        if (end <= dataset.shape[0]):\n",
    "            window = dataset.iloc[start:end, :].reset_index(drop=True)\n",
    "            win_count = win_count + 1\n",
    "            features = feature_extraction_function(window)\n",
    "\n",
    "            windowed_dataset.append(features)\n",
    "\n",
    "    final = pd.DataFrame(windowed_dataset)\n",
    "    final.insert(0, 'group', subject_id)  # to use in Subject CV\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPoQlpJGIxCn"
   },
   "outputs": [],
   "source": [
    "def Preprocessing(dataset_path, overlapping):\n",
    "    feature_function = Features\n",
    "    win_size = 3\n",
    "\n",
    "    print(\"Start for win size {}\".format(win_size))\n",
    "    datapoints_per_window = int(win_size * sample_rate)\n",
    "\n",
    "    print(feature_function.__name__)\n",
    "\n",
    "    ALL = []\n",
    "   \n",
    "    for subject in range(1,18):\n",
    "        file_path = dataset_path + '\\subject{0}_ideal.csv'.format(subject)\n",
    "        all_cols = []\n",
    "        \n",
    "        \n",
    "#########################################################################################################################\n",
    "        for i in range(2, 117, 13):# indices of accelarations\n",
    "            indices = list(range(i, i + 13))\n",
    "            all_cols.extend(indices)\n",
    "\n",
    "        all_cols.append(119)  # label index\n",
    "\n",
    "        tmp_db = pd.read_csv(file_path, header=None, usecols=all_cols, sep='\\t')\n",
    "        tmp_db.columns = list(range(tmp_db.shape[1]))  # re-index the columns\n",
    "\n",
    "        transformed_db = windowing_dataset(tmp_db, datapoints_per_window, feature_function, subject,\n",
    "                                                   overlap=overlapping)\n",
    "\n",
    "        ALL.append(transformed_db)\n",
    "#########################################################################################################################\n",
    "       \n",
    "    #final_dataset = pd.DataFrame()\n",
    "    ALL_dataset = pd.DataFrame()\n",
    "    ALL_dataset = ALL_dataset.append(ALL, ignore_index=True)\n",
    "    \n",
    "    return ALL_dataset\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39135,
     "status": "ok",
     "timestamp": 1590799556333,
     "user": {
      "displayName": "BEKRY MOHAMMEDDAWA",
      "photoUrl": "https://lh6.googleusercontent.com/-7j4JARNyQ3c/AAAAAAAAAAI/AAAAAAAAAIs/zlpWr3A2OcI/s64/photo.jpg",
      "userId": "03084319400094525820"
     },
     "user_tz": -120
    },
    "id": "_ZJHgU7gIxCs",
    "outputId": "bc61162a-1dd4-4cec-bb29-7c126f1e6a11"
   },
   "outputs": [],
   "source": [
    "def subject_cross_validation(X, Y, groups, classifier):\n",
    "    f1 = []\n",
    "    logo = LeaveOneGroupOut()\n",
    "    i = 0\n",
    "    for train_index, test_index in logo.split(X, Y, groups=groups):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        i += 1\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        f = f1_score(y_true=y_test, y_pred=y_pred, average='micro')\n",
    "        \n",
    "        print('Model-',i ,' -',' f1 score: ', f)\n",
    "       \n",
    "        f1.append(f)\n",
    "    return np.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(dataset, model):\n",
    "    results = dict()\n",
    "    win_size = float(3)\n",
    "    print('window_size = ', win_size,' sec')\n",
    "\n",
    "    dataset = dataset\n",
    "    groups = dataset['group']\n",
    "    X = dataset.iloc[:, 1:-1]\n",
    "    X = np.array(X)\n",
    "    \n",
    "    Y = dataset.iloc[:, -1]\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    for model_name, mod in model.items():\n",
    "        f1 = 0\n",
    "\n",
    "        f1 = subject_cross_validation(X, Y, groups, mod)\n",
    "\n",
    "        if win_size in results:\n",
    "            results[win_size].append(f1)\n",
    "        else:\n",
    "            results[win_size] = [f1]\n",
    "\n",
    "\n",
    "        results = collections.OrderedDict(sorted(results.items()))\n",
    "\n",
    "        final = []\n",
    "        col = list(model.keys())\n",
    "        col.insert(0, \"window-size\")\n",
    "        final.append(col)\n",
    "        for k, v in results.items():\n",
    "            tmp = []\n",
    "            tmp.append([k])\n",
    "            tmp.append(v)\n",
    "            flattened = [val for sublist in tmp for val in sublist]\n",
    "            final.append(flattened)\n",
    "\n",
    "    accuracy = final[1][1]\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = {'RF': RandomForestClassifier(n_estimators=40, random_state=42, n_jobs=-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 908479,
     "status": "ok",
     "timestamp": 1590800425696,
     "user": {
      "displayName": "BEKRY MOHAMMEDDAWA",
      "photoUrl": "https://lh6.googleusercontent.com/-7j4JARNyQ3c/AAAAAAAAAAI/AAAAAAAAAIs/zlpWr3A2OcI/s64/photo.jpg",
      "userId": "03084319400094525820"
     },
     "user_tz": -120
    },
    "id": "SJbUrsB2IxCy",
    "outputId": "769b89aa-8a18-458c-db6a-525751c02a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start for win size 3\n",
      "Features\n"
     ]
    }
   ],
   "source": [
    "dataset_csv_path = r\"D:\\projec\\proj\\data\"\n",
    "\n",
    "overlapping = 1  # input 0 for non overlapping, 1 for overlapping\n",
    "\n",
    "ALL = Preprocessing(dataset_path=dataset_csv_path, overlapping=bool(int(overlapping)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.001968</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>-0.086304</td>\n",
       "      <td>0.074317</td>\n",
       "      <td>-34.538127</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>50.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.001984</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>-0.086304</td>\n",
       "      <td>0.074317</td>\n",
       "      <td>-34.813495</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>55.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.001989</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>-0.082277</td>\n",
       "      <td>0.074317</td>\n",
       "      <td>-34.909973</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>56.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>-0.082277</td>\n",
       "      <td>0.060566</td>\n",
       "      <td>-36.305483</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>27.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.002145</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>-0.083756</td>\n",
       "      <td>0.074675</td>\n",
       "      <td>-37.644857</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>22.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.002243</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>-0.088903</td>\n",
       "      <td>0.074675</td>\n",
       "      <td>-39.361609</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>36.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.002399</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>-0.088903</td>\n",
       "      <td>0.074675</td>\n",
       "      <td>-42.105543</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>42.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.002598</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>-0.088903</td>\n",
       "      <td>0.100022</td>\n",
       "      <td>-45.600158</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>44.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.002763</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>-0.088915</td>\n",
       "      <td>0.100022</td>\n",
       "      <td>-48.490811</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>51.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.003002</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>-0.100879</td>\n",
       "      <td>0.100022</td>\n",
       "      <td>-52.681572</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>54.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   group         0         1         2         3         4          5  \\\n",
       "0      1 -0.001968  0.000467  0.000467 -0.086304  0.074317 -34.538127   \n",
       "1      1 -0.001984  0.000426  0.000426 -0.086304  0.074317 -34.813495   \n",
       "2      1 -0.001989  0.000432  0.000432 -0.082277  0.074317 -34.909973   \n",
       "3      1 -0.002069  0.000448  0.000448 -0.082277  0.060566 -36.305483   \n",
       "4      1 -0.002145  0.000453  0.000453 -0.083756  0.074675 -37.644857   \n",
       "5      1 -0.002243  0.000525  0.000525 -0.088903  0.074675 -39.361609   \n",
       "6      1 -0.002399  0.000534  0.000534 -0.088903  0.074675 -42.105543   \n",
       "7      1 -0.002598  0.000490  0.000490 -0.088903  0.100022 -45.600158   \n",
       "8      1 -0.002763  0.000549  0.000549 -0.088915  0.100022 -48.490811   \n",
       "9      1 -0.003002  0.000571  0.000571 -0.100879  0.100022 -52.681572   \n",
       "\n",
       "          6     7     8  ...       233       234       235       236  \\\n",
       "0  7.228819  50.0  74.0  ...  0.000138  0.000004  0.000016  0.000003   \n",
       "1  7.228819  55.0  80.0  ...  0.000118  0.000004  0.000016  0.000003   \n",
       "2  7.228819  56.0  78.0  ...  0.000082  0.000003  0.000017  0.000002   \n",
       "3  7.228819  27.0  82.0  ...  0.000088  0.000003  0.000017  0.000002   \n",
       "4  7.228819  22.0  95.0  ...  0.000121  0.000003  0.000018  0.000002   \n",
       "5  7.228819  36.0  87.0  ...  0.000127  0.000004  0.000017  0.000002   \n",
       "6  7.228819  42.0  72.0  ...  0.000124  0.000004  0.000016  0.000002   \n",
       "7  7.228819  44.0  59.0  ...  0.000118  0.000003  0.000017  0.000002   \n",
       "8  7.228819  51.0  54.0  ...  0.000079  0.000002  0.000016  0.000002   \n",
       "9  7.228819  54.0  61.0  ...  0.000140  0.000003  0.000017  0.000002   \n",
       "\n",
       "        237       238       239       240       241  242  \n",
       "0  0.000003  0.000002  0.000017  0.000004  0.000016    1  \n",
       "1  0.000002  0.000002  0.000016  0.000004  0.000017    1  \n",
       "2  0.000002  0.000002  0.000016  0.000004  0.000016    1  \n",
       "3  0.000003  0.000002  0.000018  0.000004  0.000014    1  \n",
       "4  0.000003  0.000002  0.000018  0.000004  0.000014    1  \n",
       "5  0.000003  0.000002  0.000017  0.000004  0.000014    1  \n",
       "6  0.000003  0.000002  0.000017  0.000004  0.000014    1  \n",
       "7  0.000002  0.000002  0.000016  0.000004  0.000015    1  \n",
       "8  0.000003  0.000002  0.000016  0.000004  0.000014    1  \n",
       "9  0.000003  0.000002  0.000017  0.000004  0.000013    1  \n",
       "\n",
       "[10 rows x 244 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL_accuracy = \n",
      "window_size =  3.0  sec\n",
      "Model- 1  -  f1 score:  0.9342657342657342\n",
      "Model- 2  -  f1 score:  0.9883679943602397\n",
      "Model- 3  -  f1 score:  0.9756\n",
      "Model- 4  -  f1 score:  0.9798072510325837\n",
      "Model- 5  -  f1 score:  0.9541379310344827\n",
      "Model- 6  -  f1 score:  0.9872222222222222\n",
      "Model- 7  -  f1 score:  1.0\n",
      "Model- 8  -  f1 score:  0.9600614439324117\n",
      "Model- 9  -  f1 score:  0.9808547008547008\n",
      "Model- 10  -  f1 score:  0.9590303857972005\n",
      "Model- 11  -  f1 score:  0.979375\n",
      "Model- 12  -  f1 score:  0.9890075376884422\n",
      "Model- 13  -  f1 score:  0.9576629974597799\n",
      "Model- 14  -  f1 score:  0.9767687434002112\n",
      "Model- 15  -  f1 score:  0.9844088349935037\n",
      "Model- 16  -  f1 score:  0.9054054054054054\n",
      "Model- 17  -  f1 score:  0.9619627234689996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9690552297597599"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('ALL_accuracy = ', )\n",
    "ALL_accuracy = classifier(dataset=ALL, model=mod)\n",
    "ALL_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d ={'ALL': [ALL_accuracy]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.969055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ALL\n",
       "0  0.969055"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2-ACC_FEATURE_extraction.ipynb",
   "provenance": [
    {
     "file_id": "1SU1QHunESAxJSZXRKHmhjFK2oy3dRKaS",
     "timestamp": 1590611182419
    },
    {
     "file_id": "1qudyr2XYqFicWtsAvxrBJFsEZ40mJH5N",
     "timestamp": 1590418899156
    },
    {
     "file_id": "1E4adU2mQqg_A46iYrGGTpls3MqY5H-ch",
     "timestamp": 1590195968440
    },
    {
     "file_id": "1uptU8_lPFhKcNrTJjB0BUhrBu_VElJhi",
     "timestamp": 1590195938409
    },
    {
     "file_id": "11oH0W5_KdmXeQu3UO6K5gyN-TwxFSTqB",
     "timestamp": 1590188536325
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
