{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JK1wiYzYIxCK"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import collections\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39184,
     "status": "ok",
     "timestamp": 1590799556318,
     "user": {
      "displayName": "BEKRY MOHAMMEDDAWA",
      "photoUrl": "https://lh6.googleusercontent.com/-7j4JARNyQ3c/AAAAAAAAAAI/AAAAAAAAAIs/zlpWr3A2OcI/s64/photo.jpg",
      "userId": "03084319400094525820"
     },
     "user_tz": -120
    },
    "id": "eMqZnTcFI1Ma",
    "outputId": "fd551f65-a5c5-4a3d-897e-b1a0af00a236"
   },
   "outputs": [],
   "source": [
    "from numba.typed import List\n",
    "from numba import jit, njit, vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39166,
     "status": "ok",
     "timestamp": 1590799556321,
     "user": {
      "displayName": "BEKRY MOHAMMEDDAWA",
      "photoUrl": "https://lh6.googleusercontent.com/-7j4JARNyQ3c/AAAAAAAAAAI/AAAAAAAAAIs/zlpWr3A2OcI/s64/photo.jpg",
      "userId": "03084319400094525820"
     },
     "user_tz": -120
    },
    "id": "L6CPZsFqIxCU",
    "outputId": "90507f9e-85b3-4f7a-eea0-68c512f50d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "sample_rate = 50  # number of observation per second based on dataset documentation(150 samples in 3 second)\n",
    "\n",
    "sliding_size = int((1/3) * sample_rate)  # number of skipped datapoints to start next window\n",
    "print(sliding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nsLxSb-5IxCa"
   },
   "source": [
    "# Feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dr03fDIIxCc"
   },
   "outputs": [],
   "source": [
    "@njit()\n",
    "def mean_crossing_rate(col):\n",
    "    # col = np.array(values)\n",
    "    normalized = col - col.mean()  # to make elements of array possitive or negetive\n",
    "    return ((normalized[:-1] * col[1:]) < 0).sum()  # Zero-Crossing_rate\n",
    "\n",
    "def get_interquartile(x):  # inter-quartile range\n",
    "    IQR = iqr(x)\n",
    "    return(IQR) \n",
    "@njit()\n",
    "def calc_sma_for_window(data):\n",
    "    return np.sum(data) / len(data)  \n",
    "@njit()\n",
    "def get_min(x):\n",
    "    m = np.min(x)\n",
    "    return m\n",
    "@njit()\n",
    "def get_max(x):\n",
    "    m = np.max(x)\n",
    "    return m\n",
    "@njit()\n",
    "def get_mean(x):\n",
    "    m = np.mean(x)\n",
    "    return m\n",
    "@njit()\n",
    "def get_var(x):\n",
    "    m = np.var(x)\n",
    "    return m\n",
    "@njit()\n",
    "def get_mean(x):\n",
    "    m = np.mean(x)\n",
    "    return m\n",
    "@njit()\n",
    "def get_sum(x):\n",
    "    m = x.sum()\n",
    "    return m \n",
    "@njit()\n",
    "def get_median(x):\n",
    "    m = np.median(x)\n",
    "    return m \n",
    "@njit()\n",
    "def get_std(x):\n",
    "    m = np.median(x)\n",
    "    return m \n",
    "@njit()\n",
    "def get_rng(x):\n",
    "    n = np.max(x)\n",
    "    m = np.min(x)\n",
    "    z = n-m\n",
    "    return z \n",
    "\n",
    "def get_rms(x, axis=None):\n",
    "    return np.sqrt(np.mean(x ** 2, axis=axis))\n",
    "\n",
    "def calc_sma_for_window(data):\n",
    "    return np.sum(data) / len(data)\n",
    "\n",
    "\n",
    "def calc_sma_adv_for_window(data):\n",
    "    return np.sum(data - np.mean(data) / len(data))\n",
    "\n",
    "\n",
    "def calc_absolutes_for_list(list):\n",
    "    return ([abs(i) for i in list])\n",
    "\n",
    "def get_sma(data): \n",
    "    sma_sim = calc_sma_for_window(data)\n",
    "    sma_adv = calc_sma_adv_for_window(data)\n",
    "\n",
    "    sma_sim_abs = calc_sma_for_window(calc_absolutes_for_list(data))\n",
    "    sma_adv_abs = calc_sma_adv_for_window(calc_absolutes_for_list(data))\n",
    "\n",
    "    return sma_sim, sma_adv, sma_sim_abs, sma_adv_abs\n",
    "\n",
    "def get_entropy(Y):\n",
    "    \"\"\"\n",
    "    Also known as Shanon Entropy\n",
    "    Reference: https://en.wikipedia.org/wiki/Entropy_(information_theory)\n",
    "    \"\"\"\n",
    "    unique, count = np.unique(Y, return_counts=True, axis=0)\n",
    "    prob = count/len(Y)\n",
    "    en = np.sum((-1)*prob*np.log2(prob))\n",
    "    return en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Energy(frame):\n",
    "    return sum( [ abs(x)**2 for x in frame ] ) / len(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram_equalization on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalize(im):#https://www.researchgate.net/publication/281118372_NumPy_SciPy_Recipes_for_Image_Processing_Intensity_Normalization_and_Histogram_Equalization\n",
    "    data = im.copy().flatten()\n",
    "    hist, bins = np.histogram(data, 256, density=True)\n",
    "    cdf = hist.cumsum()#normalized cumulative histogram H using NumPyâ€™s inbuilt function cumsum\n",
    "    cdf = 255*cdf/cdf[-1]  #intensity transformation\n",
    "    img_eq = np.interp(data, bins[:-1], cdf)\n",
    "    return img_eq.reshape(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Features(window):# mean, std,max,min and zero-crossing-rate\n",
    "    wind = window.iloc[:, :-1]\n",
    "    win = np.array(wind)\n",
    "    features = []\n",
    "    \n",
    "    features.append(get_mean(win))\n",
    "    features.append(get_median(win))\n",
    "    #features.append(get_var(win))\n",
    "    features.append(get_std(win))\n",
    "    features.append(get_min(win))\n",
    "    features.append(get_max(win))\n",
    "    #features.append(get_rng(win))\n",
    "    features.append(get_sum(win))\n",
    "    #features.append(get_rms(win))\n",
    "    #features.append(get_sma(win))\n",
    "    features.append(get_entropy(win))\n",
    "    mean_crossing = [mean_crossing_rate(win[:, i]) for i in range(win.shape[1])]\n",
    "    features.append(np.array(mean_crossing))\n",
    "    features.append(get_interquartile(win))\n",
    "    energy_measure = Energy(win)\n",
    "    features.append(np.array(energy_measure))\n",
    " \n",
    "\n",
    "    \n",
    "    features = np.hstack(features).tolist()\n",
    "    \n",
    "    label = window.iloc[:, -1].mode()[0]  ## select the most frequent label as the label of the window\n",
    "    features.append(label)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BoePfFWVIxCh"
   },
   "outputs": [],
   "source": [
    "def windowing_dataset(dataset, win_size, feature_extraction_function, subject_id, overlap=False):\n",
    "    windowed_dataset = []\n",
    "    win_count = 0\n",
    "    if overlap:\n",
    "        step_size = sliding_size  # for Overlapping technique\n",
    "    else:\n",
    "        step_size = win_size  # for Non-overlapping technique\n",
    "\n",
    "    for index in range(0, dataset.shape[0], step_size):\n",
    "        start = index\n",
    "        end = start + win_size\n",
    "        # to assure all of windows are equal in size\n",
    "        if (end <= dataset.shape[0]):\n",
    "            window = dataset.iloc[start:end, :].reset_index(drop=True)\n",
    "            win_count = win_count + 1\n",
    "            features = feature_extraction_function(window)\n",
    "\n",
    "            windowed_dataset.append(features)\n",
    "\n",
    "    final = pd.DataFrame(windowed_dataset)\n",
    "    final.insert(0, 'group', subject_id)  # to use in Subject CV\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPoQlpJGIxCn"
   },
   "outputs": [],
   "source": [
    "def Preprocessing(dataset_path, overlapping):\n",
    "    feature_function = Features\n",
    "    win_size = 3\n",
    "    #for win_size in win_sizes:\n",
    "    print(\"Start for win size {}\".format(win_size))\n",
    "    datapoints_per_window = int(win_size * sample_rate)\n",
    "\n",
    " \n",
    "    print(feature_function.__name__)\n",
    "\n",
    "    windowed_dataset = []\n",
    "\n",
    "    for subject in range(1,18):\n",
    "        file_path = dataset_path + '\\subject{0}_ideal.csv'.format(subject)\n",
    "        acc_cols = []\n",
    "        for i in range(8, 117, 13):# indices of accelarations\n",
    "            indices = list(range(i, i + 3))\n",
    "            acc_cols.extend(indices)\n",
    "\n",
    "        acc_cols.append(119)  # label index\n",
    "\n",
    "        tmp_db = pd.read_csv(file_path, header=None, usecols=acc_cols, sep='\\t')\n",
    "        tmp_db.columns = list(range(tmp_db.shape[1]))  # re-index the columns\n",
    "        \n",
    "        transformed_db = windowing_dataset(tmp_db, datapoints_per_window, feature_function, subject,\n",
    "                                                   overlap=overlapping)\n",
    "\n",
    "        windowed_dataset.append(transformed_db)\n",
    "\n",
    "    final_dataset = pd.DataFrame()\n",
    "    \n",
    "    final_dataset = final_dataset.append(windowed_dataset, ignore_index=True)\n",
    "    return final_dataset\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39135,
     "status": "ok",
     "timestamp": 1590799556333,
     "user": {
      "displayName": "BEKRY MOHAMMEDDAWA",
      "photoUrl": "https://lh6.googleusercontent.com/-7j4JARNyQ3c/AAAAAAAAAAI/AAAAAAAAAIs/zlpWr3A2OcI/s64/photo.jpg",
      "userId": "03084319400094525820"
     },
     "user_tz": -120
    },
    "id": "_ZJHgU7gIxCs",
    "outputId": "bc61162a-1dd4-4cec-bb29-7c126f1e6a11"
   },
   "outputs": [],
   "source": [
    "def subject_cross_validation(X, Y, groups, classifier):\n",
    "    f1 = []\n",
    "    logo = LeaveOneGroupOut()\n",
    "    i = 0\n",
    "    for train_index, test_index in logo.split(X, Y, groups=groups):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        i += 1\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        f = f1_score(y_true=y_test, y_pred=y_pred, average='micro')\n",
    "        \n",
    "        print('Model-',i ,' -',' f1 score: ', f)\n",
    "       \n",
    "        f1.append(f)\n",
    "    return np.mean(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(dataset, model):\n",
    "    results = dict()\n",
    "    win_size = float(3)\n",
    "    print('window_size = ', win_size,' sec')\n",
    "\n",
    "    dataset = dataset\n",
    "    groups = dataset['group']\n",
    "    X = dataset.iloc[:, 1:-1]\n",
    "    X = np.array(X)\n",
    "    features = histogram_equalize(X)\n",
    "    X = features\n",
    "    Y = dataset.iloc[:, -1]\n",
    "    Y = np.array(Y)\n",
    "\n",
    "\n",
    "    for model_name, mod in model.items():\n",
    "        f1 = 0\n",
    "\n",
    "\n",
    "        f1 = subject_cross_validation(X, Y, groups, mod)\n",
    "\n",
    "        if win_size in results:\n",
    "            results[win_size].append(f1)\n",
    "        else:\n",
    "            results[win_size] = [f1]\n",
    "\n",
    " \n",
    "        results = collections.OrderedDict(sorted(results.items()))\n",
    "\n",
    "        final = []\n",
    "        col = list(model.keys())\n",
    "        col.insert(0, \"window-size\")\n",
    "        final.append(col)\n",
    "        for k, v in results.items():\n",
    "            tmp = []\n",
    "            tmp.append([k])\n",
    "            tmp.append(v)\n",
    "            flattened = [val for sublist in tmp for val in sublist]\n",
    "            final.append(flattened)\n",
    "\n",
    "        print('accuracy : ', final[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = {'RF': RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 908479,
     "status": "ok",
     "timestamp": 1590800425696,
     "user": {
      "displayName": "BEKRY MOHAMMEDDAWA",
      "photoUrl": "https://lh6.googleusercontent.com/-7j4JARNyQ3c/AAAAAAAAAAI/AAAAAAAAAIs/zlpWr3A2OcI/s64/photo.jpg",
      "userId": "03084319400094525820"
     },
     "user_tz": -120
    },
    "id": "SJbUrsB2IxCy",
    "outputId": "769b89aa-8a18-458c-db6a-525751c02a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start for win size 3\n",
      "Features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.122687</td>\n",
       "      <td>0.054137</td>\n",
       "      <td>0.054137</td>\n",
       "      <td>-0.48366</td>\n",
       "      <td>0.87089</td>\n",
       "      <td>496.881671</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>90.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357448</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.016382</td>\n",
       "      <td>0.622709</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.039999</td>\n",
       "      <td>0.409673</td>\n",
       "      <td>0.065249</td>\n",
       "      <td>0.081963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.122757</td>\n",
       "      <td>0.057163</td>\n",
       "      <td>0.057163</td>\n",
       "      <td>-0.47624</td>\n",
       "      <td>0.87089</td>\n",
       "      <td>497.163854</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>79.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357240</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.018390</td>\n",
       "      <td>0.619513</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.041156</td>\n",
       "      <td>0.413741</td>\n",
       "      <td>0.068959</td>\n",
       "      <td>0.064359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.122488</td>\n",
       "      <td>0.058662</td>\n",
       "      <td>0.058662</td>\n",
       "      <td>-0.48879</td>\n",
       "      <td>0.87089</td>\n",
       "      <td>496.077094</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>75.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357556</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.021844</td>\n",
       "      <td>0.613512</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.055832</td>\n",
       "      <td>0.437328</td>\n",
       "      <td>0.062415</td>\n",
       "      <td>0.059816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.124067</td>\n",
       "      <td>0.056789</td>\n",
       "      <td>0.056789</td>\n",
       "      <td>-0.54691</td>\n",
       "      <td>0.87089</td>\n",
       "      <td>502.472614</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>22.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360712</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.020669</td>\n",
       "      <td>0.619554</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.061742</td>\n",
       "      <td>0.459112</td>\n",
       "      <td>0.052358</td>\n",
       "      <td>0.067397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.123859</td>\n",
       "      <td>0.051037</td>\n",
       "      <td>0.051037</td>\n",
       "      <td>-0.88797</td>\n",
       "      <td>0.87089</td>\n",
       "      <td>501.629499</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>15.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365645</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>0.622811</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.059275</td>\n",
       "      <td>0.467472</td>\n",
       "      <td>0.047577</td>\n",
       "      <td>0.067944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.132113</td>\n",
       "      <td>0.053992</td>\n",
       "      <td>0.053992</td>\n",
       "      <td>-0.90571</td>\n",
       "      <td>1.15230</td>\n",
       "      <td>535.056464</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>122.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370472</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>0.017924</td>\n",
       "      <td>0.626765</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.053164</td>\n",
       "      <td>0.452130</td>\n",
       "      <td>0.049836</td>\n",
       "      <td>0.075622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.144107</td>\n",
       "      <td>0.061380</td>\n",
       "      <td>0.061380</td>\n",
       "      <td>-0.90571</td>\n",
       "      <td>1.28550</td>\n",
       "      <td>583.632754</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>109.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368724</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.017406</td>\n",
       "      <td>0.640130</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.042975</td>\n",
       "      <td>0.440110</td>\n",
       "      <td>0.051009</td>\n",
       "      <td>0.077333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.148660</td>\n",
       "      <td>0.064782</td>\n",
       "      <td>0.064782</td>\n",
       "      <td>-0.90571</td>\n",
       "      <td>1.28550</td>\n",
       "      <td>602.073996</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>94.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366515</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.020518</td>\n",
       "      <td>0.631268</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.048118</td>\n",
       "      <td>0.455538</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.058612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.162770</td>\n",
       "      <td>0.084191</td>\n",
       "      <td>0.084191</td>\n",
       "      <td>-0.90571</td>\n",
       "      <td>1.60600</td>\n",
       "      <td>659.219834</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>80.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364613</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.022959</td>\n",
       "      <td>0.628192</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.056832</td>\n",
       "      <td>0.463414</td>\n",
       "      <td>0.048845</td>\n",
       "      <td>0.073784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.171879</td>\n",
       "      <td>0.080777</td>\n",
       "      <td>0.080777</td>\n",
       "      <td>-0.90571</td>\n",
       "      <td>1.64620</td>\n",
       "      <td>696.108205</td>\n",
       "      <td>7.228819</td>\n",
       "      <td>66.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365145</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.629799</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.056577</td>\n",
       "      <td>0.479525</td>\n",
       "      <td>0.042276</td>\n",
       "      <td>0.069691</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   group         0         1         2        3        4           5  \\\n",
       "0      1  0.122687  0.054137  0.054137 -0.48366  0.87089  496.881671   \n",
       "1      1  0.122757  0.057163  0.057163 -0.47624  0.87089  497.163854   \n",
       "2      1  0.122488  0.058662  0.058662 -0.48879  0.87089  496.077094   \n",
       "3      1  0.124067  0.056789  0.056789 -0.54691  0.87089  502.472614   \n",
       "4      1  0.123859  0.051037  0.051037 -0.88797  0.87089  501.629499   \n",
       "5      1  0.132113  0.053992  0.053992 -0.90571  1.15230  535.056464   \n",
       "6      1  0.144107  0.061380  0.061380 -0.90571  1.28550  583.632754   \n",
       "7      1  0.148660  0.064782  0.064782 -0.90571  1.28550  602.073996   \n",
       "8      1  0.162770  0.084191  0.084191 -0.90571  1.60600  659.219834   \n",
       "9      1  0.171879  0.080777  0.080777 -0.90571  1.64620  696.108205   \n",
       "\n",
       "          6      7      8  ...        53        54        55        56  \\\n",
       "0  7.228819   90.0   68.0  ...  0.357448  0.003657  0.016382  0.622709   \n",
       "1  7.228819   79.0   60.0  ...  0.357240  0.003706  0.018390  0.619513   \n",
       "2  7.228819   75.0   64.0  ...  0.357556  0.003362  0.021844  0.613512   \n",
       "3  7.228819   22.0   68.0  ...  0.360712  0.003069  0.020669  0.619554   \n",
       "4  7.228819   15.0  132.0  ...  0.365645  0.003815  0.019958  0.622811   \n",
       "5  7.228819  122.0  120.0  ...  0.370472  0.004258  0.017924  0.626765   \n",
       "6  7.228819  109.0  115.0  ...  0.368724  0.004034  0.017406  0.640130   \n",
       "7  7.228819   94.0   77.0  ...  0.366515  0.003950  0.020518  0.631268   \n",
       "8  7.228819   80.0   45.0  ...  0.364613  0.003329  0.022959  0.628192   \n",
       "9  7.228819   66.0   93.0  ...  0.365145  0.003643  0.020482  0.629799   \n",
       "\n",
       "         57        58        59        60        61  62  \n",
       "0  0.003304  0.039999  0.409673  0.065249  0.081963   1  \n",
       "1  0.003458  0.041156  0.413741  0.068959  0.064359   1  \n",
       "2  0.003560  0.055832  0.437328  0.062415  0.059816   1  \n",
       "3  0.003909  0.061742  0.459112  0.052358  0.067397   1  \n",
       "4  0.003878  0.059275  0.467472  0.047577  0.067944   1  \n",
       "5  0.003271  0.053164  0.452130  0.049836  0.075622   1  \n",
       "6  0.002997  0.042975  0.440110  0.051009  0.077333   1  \n",
       "7  0.002740  0.048118  0.455538  0.052813  0.058612   1  \n",
       "8  0.002816  0.056832  0.463414  0.048845  0.073784   1  \n",
       "9  0.004148  0.056577  0.479525  0.042276  0.069691   1  \n",
       "\n",
       "[10 rows x 64 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_csv_path = r\"D:\\projec\\proj\\data\"\n",
    "\n",
    "overlapping = 1   # input 0 for nonoverlapping , 1 for overlapping\n",
    "\n",
    "df = Preprocessing(dataset_path=dataset_csv_path, overlapping=bool(int(overlapping)))\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size =  3.0  sec\n",
      "Model- 1  -  f1 score:  0.8125874125874126\n",
      "Model- 2  -  f1 score:  0.8103630595699682\n",
      "Model- 3  -  f1 score:  0.7768\n",
      "Model- 4  -  f1 score:  0.934832491968793\n",
      "Model- 5  -  f1 score:  0.6610344827586206\n",
      "Model- 6  -  f1 score:  0.7572222222222222\n",
      "Model- 7  -  f1 score:  0.9944598337950139\n",
      "Model- 8  -  f1 score:  0.8218125960061444\n",
      "Model- 9  -  f1 score:  0.8516239316239316\n",
      "Model- 10  -  f1 score:  0.8443154660293616\n",
      "Model- 11  -  f1 score:  0.9559375\n",
      "Model- 12  -  f1 score:  0.9469221105527639\n",
      "Model- 13  -  f1 score:  0.8097657352526108\n",
      "Model- 14  -  f1 score:  0.9204505455825414\n",
      "Model- 15  -  f1 score:  0.8834993503681248\n",
      "Model- 16  -  f1 score:  0.7720964207450693\n",
      "Model- 17  -  f1 score:  0.8634461772537086\n",
      "accuracy :  0.8480687844891933\n"
     ]
    }
   ],
   "source": [
    "dataset = df\n",
    "\n",
    "classifier(dataset=dataset, model=mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2-ACC_FEATURE_extraction.ipynb",
   "provenance": [
    {
     "file_id": "1SU1QHunESAxJSZXRKHmhjFK2oy3dRKaS",
     "timestamp": 1590611182419
    },
    {
     "file_id": "1qudyr2XYqFicWtsAvxrBJFsEZ40mJH5N",
     "timestamp": 1590418899156
    },
    {
     "file_id": "1E4adU2mQqg_A46iYrGGTpls3MqY5H-ch",
     "timestamp": 1590195968440
    },
    {
     "file_id": "1uptU8_lPFhKcNrTJjB0BUhrBu_VElJhi",
     "timestamp": 1590195938409
    },
    {
     "file_id": "11oH0W5_KdmXeQu3UO6K5gyN-TwxFSTqB",
     "timestamp": 1590188536325
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
